# -- Pod replica count
replicaCount: 1

image:
  repository: ghcr.io/datatok/zeppelin-server
  pullPolicy: IfNotPresent
  tag: ""

# -- To use private images
imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: ""
  rbac:
    create: true

podAnnotations: {}

podLabels: {}

# -- see https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
podSecurityContext: {}
#  runAsNonRoot: true
#  runAsUser: 1000
#  runAsGroup: 1000
#  fsGroup: 1000

# -- see https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
securityContext: {}
#  capabilities:
#    drop:
#     - ALL
#  allowPrivilegeEscalation: false
#  readOnlyRootFilesystem: true

networkPolicy:
  # -- enable network policy
  enabled: false
  # -- add extra NP egress rules
  extraEgressRules: []
  # -- add extra NP ingress rules
  extraIngressRules: []

# -- extraVolumes Array to add extra volumes
extraVolumes: []
# - name: toto
#   emptyDir: {}

# -- extraVolumeMounts Array to add extra mount
extraVolumeMounts: []
# - name: toto
#   mountPath: /app/toto

# -- extra env variables for zeppelin container
extraEnvVars: #{}
- name: hello
  value: world

service:
  type: ClusterIP
  # -- HTTP server port
  port: 8080
  # -- RPC port, to register interpreter
  rpcPort: 38853

ingress:
  # -- Enable Zeppelin server ingress
  enabled: false
  # -- Annotations to use cert-manager and sticky sessions
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    # nginx.ingress.kubernetes.io/affinity: "cookie"
    # nginx.ingress.kubernetes.io/session-cookie-name: "zep"
    # nginx.ingress.kubernetes.io/session-cookie-expires: "172800"
    # nginx.ingress.kubernetes.io/session-cookie-max-age: "172800"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

# -- Resources, dont be greedy for memory, this is java :-)
resources: {}
#  limits:
#    cpu: 1000m
#    memory: 1024Mi
#  requests:
#    cpu: 100m
#    memory: 256Mi

nodeSelector: {}

tolerations: []

affinity: {}

# -- Define volume to store conf
volumeConf:
  type: emptyDir

# -- Define volume to store notebooks (emptyDir or pvc)
volumeNotebooks:
  type: emptyDir

# volumeNotebooks:
#   type: pvc
#   spec:
#     accessModes:
#     - ReadWriteOnce
#     resources:
#       requests:
#         storage: 8Gi
#     storageClassName: rbd

# -- Define volume to store tmp (emptyDir or pvc)
volumeTmp:
  type: emptyDir

zeppelin:
  partOf: data-lake

  # -- fill zeppelin-site.xml
  properties:
    # -- IP to listen to (usually `0.0.0.0`)
    zeppelin.server.addr: 0.0.0.0
    # -- notebooks storage dir
    zeppelin.notebook.dir: notebook
    # -- Context Path of the Web Application (usually `/`)
    zeppelin.server.context.path: /
    # -- id of notebook to be displayed in homescreen. ex) 2A94M5J1Z Empty value displays default home screen
    zeppelin.notebook.homescreen: "2H6ZG3C3D"
    # -- hide homescreen notebook from list when this value set to true
    zeppelin.notebook.homescreen.hide: "false"
    # -- Output message from interpreter exceeding the limit will be truncated
    zeppelin.interpreter.output.limit: "102400"
    # -- Interpreter process connect timeout in msec
    zeppelin.interpreter.connect.timeout: "1200000"

  server:
    # -- Zeppelin Java process memory options
    jvmMemOptions: -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -XX:MaxRAMFraction=1 -Xms512m -Xmx512m -XX:MaxMetaspaceSize=512m

  interpreter:
    # -- zeppelin interpreter inside zeppelin container or external
    # mode: embedded
    mode: external
    # -- K8S interpreter container image
    # -- see https://github.com/orgs/datatok/packages?repo_name=docker-zeppelin
    image:
      repository: ghcr.io/datatok/zeppelin-interpreter-spark
      tag: "0.10.1-edge"
    # -- K8S config-map to define K8S template (must exist)
    specTemplateConfigMap: "zep-int-zeppelin-interpreter-spec"
    ## -- thrift port (default 10000)
    thriftPort: 10000

logging:
  level: INFO
  syslog: {}
    # level: INFO
    # host:
    # port:
    # facility:
    # pattern:

notebookStorage:
  # -- Kind of storage for notebook
  type: git
  # -- if type is `git` , use this secret to get the repository URL (usually the URL contains an access token)
  repositorySecret: git-data-lake
  # -- git user name
  userName: zeppelin
  # -- git user email
  userEmail: zeppelin@apache.org

##
# Several ways to run spark notebook code:
# - driver (aka Zep' interpreter Spark application) can run
#   - within zeppelin pod (mode `local`)
#   - as a separate Deployment (mode `external`, see zeppelin-int Helm chart)
# - worker(s) can run:
#   - zeppelin pod (`embedded` mode)
#   - zeppelin interpreter pod (`local` mode)
#   - Spark cluster
#   - k8s
##
spark:
  # -- Spark linux user name (must exist)
  user: zeppelin
  # -- Spark driver settings
  driver:
    # -- Spark UI port, usually 4040
    uiPort: 4040
    # -- Create an ingress to access to Spark UI
    ingress:
      enabled: false
  # -- Spark configuration
  config: {}
  #  spark.master: local[*]
  #  spark.hadoop.hive.metastore.uris: thrift://XXXX:9083
  #  spark.executor.memory: 1G
  #  spark.app.name: zep
  # -- Spark Zeppelin interpreter properties
  interpreterProperties:
    spark.webui.yarn.useProxy:
      description: whether use yarn proxy url as spark weburl, e.g. http://localhost:8088/proxy/application_1583396598068_0004
      type: checkbox
      value: false
    zeppelin.spark.deprecatedMsg.show:
      description: Whether show the spark deprecated message, spark 2.2 and before are
        deprecated. Zeppelin will display warning message by default
      type: checkbox
      value: true
    zeppelin.spark.enableSupportedVersionCheck:
      description: Whether checking supported spark version. Developer only setting, not
        for production use
      type: checkbox
      value: true
    zeppelin.spark.maxResult:
      description: Max number of Spark SQL result to display.
      type: number
      value: '1000'
    zeppelin.spark.printREPLOutput:
      description: Print scala REPL output
      type: checkbox
      value: true
    zeppelin.spark.run.asLoginUser:
      description: Whether run spark job as the zeppelin login user, it is only applied
        when running spark job in hadoop yarn cluster and shiro is enabled
      type: checkbox
      value: true
    zeppelin.spark.scala.color:
      description: Whether enable color output of spark scala interpreter
      type: checkbox
      value: true
    zeppelin.spark.ui.hidden:
      description: Whether hide spark ui in zeppelin ui
      type: checkbox
      value: false
    zeppelin.spark.uiWebUrl:
      description: 'Override Spark UI default URL. In Kubernetes mode, value can be Jinja
        template string with 3 template variables ''PORT'', ''SERVICE_NAME'' and ''SERVICE_DOMAIN''. '
      type: string
      value: ''
    zeppelin.spark.useHiveContext:
      description: Use HiveContext instead of SQLContext if it is true. Enable hive for
        SparkSession.
      type: checkbox
      value: true
  # zeppelin.spark.concurrentSQL: "true"
  # -- if driver mode is `embedded`, PVC to use to get spark home artifacts
  homeArtifactsVolumeClaim: zeppelin-spark-artifacts

  # -- download dependencies via an init container to use proxy only for this
  dependencies: {}
  #  packages:
  #  - org.elasticsearch:elasticsearch-spark-20_2.10:7.14.0
  #  proxy:
  #    host: 10.100.X.X
  #    port: 8080
